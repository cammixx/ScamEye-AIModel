# -*- coding: utf-8 -*-
"""ml_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/139gqpsBetqTOkkqbm2ZOWzhTDLD4DMuV
"""

import pandas as pd

# Replace this with your actual file name
df = pd.read_csv("dataset.csv")

# Show the shape and first few rows
print(df.shape)
print(df.columns)
print(df.head())

import re

# Feature engineering function
def extract_features(url):
    features = {}
    features["url_length"] = len(url)
    features["num_dots"] = url.count('.')
    features["num_hyphens"] = url.count('-')
    features["num_at"] = url.count('@')
    features["num_question_marks"] = url.count('?')
    features["num_equals"] = url.count('=')
    features["num_underscores"] = url.count('_')
    features["num_ampersands"] = url.count('&')
    features["num_percent"] = url.count('%')
    features["num_digits"] = sum(c.isdigit() for c in url)
    features["has_https"] = int("https" in url.lower())
    features["has_ip_address"] = int(bool(re.search(r'(\d{1,3}\.){3}\d{1,3}', url)))

    # Common phishing keywords
    suspicious_keywords = ['secure', 'account', 'update', 'login', 'signin', 'verify', 'bank', 'ebay', 'paypal']
    features["has_suspicious_words"] = int(any(word in url.lower() for word in suspicious_keywords))

    return pd.Series(features)

# Apply to all rows
features_df = df['url'].apply(extract_features)

# Combine features with the label
data = pd.concat([features_df, df['result']], axis=1)

print(data.head())

# Start by keeping the original columns we want
full_data = pd.concat([df[['url', 'label']], features_df, df['result']], axis=1)

# Save to CSV
full_data.to_csv("url_features_full.csv", index=False)

print("âœ… Saved as url_features_full.csv")

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd

# Load our processed CSV
df = pd.read_csv("url_features_full.csv")

# Features and labels
X = df.drop(columns=["url", "label", "result"])
y = df["result"]

# Split into train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Eval
print("âœ… Accuracy:", accuracy_score(y_test, y_pred))
print("\nðŸ“Š Classification Report:\n", classification_report(y_test, y_pred))
print("\nðŸ§® Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import joblib

# Save the trained model
joblib.dump(model, "malicious_url_model.pkl")

print("âœ… Model saved as malicious_url_model.pkl")